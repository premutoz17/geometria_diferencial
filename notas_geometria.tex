\documentclass{book}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage[mathscr,mathcal]{euscript}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{shapepar}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{color}
\usepackage{shapepar}

\newtheorem{theorem}{Teorema}[section]
\newtheorem{proposition}{Proposición}[section]
\newtheorem{definition}{Definición}[section]
\newtheorem{axiom}{Axioma}
\newtheorem{corollary}{Corolario}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem*{remark}{Remark}

\title{Notas de Geometría Diferencial.}
\author{Carlos Francisco Flores Galicia.}
\date{}

\begin{document}
 
\maketitle

\chapter{Funciones de $\mathbb{R}$ a $\mathbb{R}^n$.}
\subsection{Funciones vectoriales y algunas de sus propiedades.}

%Falta agregar curvatura y que no se cumple el teorema del valor medio. Tambien el teorema de que si es diferenciable entonces es continua%

Llamaremos función vectorial de variable real o simplemente función vectorial, a aquellas con dominio en
un subconjunto de $\mathbb{R}$ y codominio en un espacio vectorial $\mathbb{R}^n$.

\begin{center}
    $f:U \subseteq \mathbb{R} \rightarrow \mathbb{R}^n$
\end{center}

Puesto que $f(x)$ es elemento de $\mathbb{R}^n$, éste tiene $n$ coordenadas, las cuales son en general, funciones de la variable $x$. Así podemos escribir

\begin{center}
    $f(x)=(f_1(x),f_2(x),...,f_n(x))$
\end{center}

Por otra parte, el dominio de una función vectorial es la intersección de los dominios de cada componente $f_i(x)$.

\begin{center}
    $\displaystyle Dom(f(x))= \bigcap^n_{i=1}f_i(x)$
\end{center}

\begin{definition}
Sean $f:U \subseteq \mathbb{R} \rightarrow \mathbb{R}^n$,  $g:V \subseteq \mathbb{R} \rightarrow \mathbb{R}^n$ y $u:W \subseteq \mathbb{R} \rightarrow \mathbb{R}$ funciones, entonces \\[1\baselineskip]
a) $(f+g)(x)=f(x)+g(x)$\\[0\baselineskip]
b) $(uf)(x)=u(x)f(x)$\\[0\baselineskip]
c) $(f \cdot g)(x)=f(x) \cdot g(x)$\\[0\baselineskip]
d) $(f \times g)(x)=f(x) \times g(x)$ si $f(x),g(x) \in \mathbb{R}^3$\\[0\baselineskip]
\end{definition}
\subsection{Límites}
\begin{definition}
Sea $f:U \subseteq \mathbb{R} \rightarrow \mathbb{R}^n$ una función vectorial. El límite de $f$ cuando $x$ tiende a $x_o$ es $L$, y se expresa como $\displaystyle \lim_{x \to x_o}f(x)=L$, si y solo si para todo $\epsilon > 0$ existe algún $\delta > 0$ tal que, para todo $x$, si $0<|x-x_o|<\delta$ entonces $||f(x)-L||<\epsilon$.
\end{definition}
\begin{theorem}
Sea $f:U \subseteq \mathbb{R} \rightarrow \mathbb{R}^n$ una función vectorial, donde se tiene que $f(x)=(f_1(x),f_2(x),...,f_n(x))$. Entonces $\displaystyle \lim_{x \to x_o}f(x)=L=(l_1,l_2,...,l_n)$ existe si y solo si existe cada limite $\displaystyle \lim_{x \to x_o}f_i(x)=l_i$.
\end{theorem}
\begin{proof}
 Supongamos que $\displaystyle \lim_{x \to x_o}f(x)=L=(l_1,l_2,...,l_n)$ existe. Entonces para todo $\epsilon > 0$ existe algún $\delta > 0$ tal que, para todo $x$, si $0<|x-x_o|<\delta$ entonces $||f(x)-L||<\epsilon$. Pero como 
 
 \begin{center}
    $||f(x)-L||=||f_1(x)-l_1, f_1(x)-l_1,...,f_n(x)-l_n||$ \\[1\baselineskip]
    $\displaystyle = \sqrt{\sum_{i=1}^{n}(f_i(x)-l_i)^2} \ <\epsilon$
\end{center}

Se tiene que 

 \begin{center}
    $|f_i(x)-l_i|=\sqrt{(f_i(x)-l_i)^2}\leq \displaystyle \sqrt{\sum_{i=1}^{n}(f_i(x)-l_i)^2}$$\ <\epsilon$
\end{center}

Por tanto, como cada $|f_i(x)-l_i|<\epsilon$ para todo $0<i\leq n$ y existe $\delta > 0$ tal que $0<|x-x_o|<\delta$, entonces $\displaystyle \lim_{x \to x_o}f_i(x)=l_i$ existe.
\\[1\baselineskip]
Por otra parte, supongamos que cada limite $\displaystyle \lim_{x \to x_o}f_i(x)=l_i$ existe. Entonces para los $\epsilon_i >0$ existen $\delta_i >0$ con $0<i\leq n$, tales que si $0<|x-x_o|<\delta_i$ entonces $|f_i(x)-l_i|<\epsilon_i$. Sea $\epsilon >0$, luego definamos $\epsilon_i =\frac{\epsilon}{\sqrt{n}}$ y $\delta=min(\delta_1,...,\delta_n)$. Para este $\delta$ se tiene que si $0<|x-x_o|<\delta$ entonces $|f_i(x)-l_i|<\frac{\epsilon}{\sqrt{n}}$. Luego

\begin{center}
       $||f(x)-L||=\displaystyle \sqrt{\sum_{i=1}^{n}(f_i(x)-l_i)^2}$$\displaystyle\ < \sqrt{\sum_{i=1}^{n}(\frac{\epsilon}{\sqrt{n}})^2}$$\ =\epsilon$
\end{center}

Por lo tanto $\displaystyle \lim_{x \to x_o}f(x)=L$.
\end{proof}
\begin{theorem}
Sea $f:U \subseteq \mathbb{R} \rightarrow \mathbb{R}^n$ una función vectorial. Si $\displaystyle \lim_{x \to x_o}f(x)=L_1$ y $\displaystyle \lim_{x \to x_o}f(x)=L_2$ entonces $L_1=L_2$. 
\end{theorem}
\begin{proof}
 Probémoslo por contradicción, es decir, supongamos que $L_1 \neq L_2$. Por hipótesis tenemos que para todo $\epsilon > 0$ existe algún $\delta_1 > 0$ tal que, para todo $x$, si $0 < |x-x_o| < \delta_1$ entonces $||f(x)-L_1|| < \epsilon$. Por otra parte, también por hipótesis se tiene que para todo $\epsilon > 0$ existe algún $\delta_2 > 0$ tal que, para todo $x$, si $0 < |x-x_o| < \delta_2$ entonces $||f(x)-L_2|| < \epsilon$. Sea $\delta=min(\delta_1, \delta_2)$. Para completar la demostración, tomemos un $\epsilon > 0$ para el cual no puedan verificarse simultáneamente las condiciones de que $||f(x)-L_1|| < \epsilon$ y $||f(x)-L_2|| < \epsilon$. Como $L_1 \neq L_2$, entonces $||L_1-L_2|| > 0$, así que tomemos $\epsilon=\frac{||L_1-L_2||}{2}$. En consecuencia se cumple que 
 
 \begin{center}
       $||f(x)-L_1||<\frac{||L_1-L_2||}{2}$ y $||f(x)-L_2||<\frac{||L_1-L_2||}{2}$
\end{center}

Esto implica que para $0<|x-x_o|<\delta$ se verifica

\begin{center}
       $||L_1-L_2||=||L_1-f(x)+f(x)-L_2||$
        \\[1\baselineskip]
       $\leq||L_1-f(x)||+||L_2-f(x)||$
        \\[1\baselineskip]
       $<\frac{||L_1-L_2||}{2}+\frac{||L_1-L_2||}{2}=||L_1-L_2||$
\end{center}

Esto es una contradicción, por lo tanto $L_1=L_2$.
\end{proof}
\subsection{Continuidad}
\begin{definition}
Sea $f:U \subseteq \mathbb{R} \rightarrow \mathbb{R}^n$ una función vectorial. Se dice que $f$ es continua en $x_o\in U$ si y solo si
\begin{center}
       $\displaystyle \lim_{x \to x_o}f(x)=f(x_o)$
\end{center}
\end{definition}
\begin{theorem}
Sea $f:U \subseteq \mathbb{R} \rightarrow \mathbb{R}^n$ una función vectorial tal que $f(x)=(f_1(x),...,f_n(x))$. Entonces $f$ es continua en $x_o\in U$ si y solo si $f_1,...,f_n$ son continuas en $x_o$.
\end{theorem}
\begin{proof}
 Supongamos que $f$ es continua en $x_o$, entonces se cumple que $\displaystyle \lim_{x \to x_o}f(x)=f(x_o)$. Por otra parte, $\displaystyle \lim_{x \to x_o}f(x)=(\lim_{x \to x_o}f_1(x),...,\lim_{x \to x_o}f_n(x))$ y también $f(x_o)=(f_1(x_o),...,f_n(x_0))$, pero por hipótesis estas dos expresiones son iguales, entonces  $\displaystyle(\lim_{x \to x_o}f_1(x),...,\lim_{x \to x_o}f_n(x))=(f(x_o)=(f_1(x_o),...,f_n(x_0))$. Así que por definicion de igualdad de vectores, se cumple entonces que $\displaystyle \lim_{x \to x_o}f_1(x)=f_1(x_o),...,\lim_{x \to x_o}f_n(x)=f_n(x_o)$. Por lo tanto $f_1,...,f_n$ son continuas en $x_o$.
 \\[1\baselineskip]
 La demostración de la segunda implicación se sigue de los pasos de la primera implicación vistos de regreso.
\end{proof}
%Añadir propiedades de las funciones continuas%
\subsection{Derivadas}
\begin{definition}
Sea $f:U \subseteq \mathbb{R} \rightarrow \mathbb{R}^n$ una función vectorial siendo $U$ un intervalo abierto y $x_o\in \mathbb{R}$. La derivada de $f$ en $x_o$, denotada por $f'(x_o)$ es \begin{center}
       $\displaystyle f'(x_o)=\lim_{h \to 0}\frac{f(x_o+h)-f(x_o)}{h}$
\end{center}
Cuando este límite existe.
\end{definition}
\begin{theorem}
Sea $f:U \subseteq \mathbb{R} \rightarrow \mathbb{R}^n$ una función vectorial siendo $U$ un intervalo abierto y $x_o\in \mathbb{R}$. La derivada $f'(x_o)$ existe si y solo si cada derivada $f'_1(x_o),...,f'_n(x_o)$ existe.
\end{theorem}
\begin{proof}
 Supongamos que $f'(x_o)$ existe, entonces 
\begin{center}
       $\displaystyle f'(x_o)=\lim_{h \to 0}\frac{f(x_o+h)-f(x_o)}{h}$
\end{center}
\begin{center}
       $=\displaystyle \lim_{h \to 0}\left(\frac{(f_1(x_o+h),f_2(x_o+h),...,f_n(x_o+h))-(f_1(x_o),f_2(x_o),...,f_n(x_o))}{h}\right)$
\end{center}
\begin{center}
       $=\displaystyle \lim_{h \to 0}\left(\frac{f_1(x_o+h)-f_1(x_o)}{h},\frac{f_2(x_o+h)-f_2(x_o)}{h},...,\frac{f_n(x_o+h)-f_n(x_o)}{h}\right)=$
\end{center}
\begin{center}
       $\displaystyle  \left(\lim_{h \to 0} \frac{f_1(x_o+h)-f_1(x_o)}{h},\lim_{h \to 0} \frac{f_2(x_o+h)-f_2(x_o)}{h},...,\lim_{h \to 0} \frac{f_n(x_o+h)-f_n(x_o)}{h}\right)$
\end{center}
Por el teorema 1.0.1, cada límite $\displaystyle \lim_{h \to 0} \frac{f_i(x_o+h)-f_i(x_o)}{h}$ existe, por lo tanto cada derivada $f'_1(x_o),...,f'_n(x_o)$ existe.\\\\
La demostración de la segunda implicación se sigue de los pasos de la primera implicación vistos de regreso. 
\end{proof}
\begin{definition}
La derivada $f'(x_o)$ de una función vectorial $f$ puede ser asociada a una matriz $n\times 1$, la cual es
conocida como la matriz Jacobiana de $f$ en el punto $x_o$, y se denota por

\begin{center}
$Jf(x_o)=\begin{bmatrix}
  f'_1(x_o) \\
  \vdots \\
  f'_n(x_o)
\end{bmatrix}$
\end{center}
\end{definition}
\begin{theorem}
Sean $f$, $g$ funciones vectoriales y $u$ una función real, todas diferenciables, entonces\\\\
a) $(f+g)'(x)=f'(x)+g'(x)$\\
b) $(uf)'(x)=u'(x)f(x)+u(x)f'(x)$\\
c) $(f \cdot g)'(x)=f'(x) \cdot g(x)+f(x) \cdot g'(x)$\\
d) $(f \times g)'(x)=f'(x) \times g(x)+f(x) \times g'(x)$ si $f,g \in \mathbb{R}^3$\\
\end{theorem}
\begin{proof}
 a)\\
 \begin{center}
 $(f+g)'(x)=\displaystyle \lim_{h \to 0}\frac{(f+g)(x_o+h)-(f+g)(x_o)}{h}$
 \end{center}
 \begin{center}
 $=\displaystyle \lim_{h \to 0}\frac{f(x_o+h)+g(x_o+h)-\left[f(x_o)+g(x_o)\right]}{h}$
 \end{center}
 \begin{center}
 $=\displaystyle \lim_{h \to 0}\frac{f(x_o+h)+g(x_o+h)-f(x_o)-g(x_o)}{h}$
 \end{center}
 \begin{center}
 $=\displaystyle \lim_{h \to 0}\frac{f(x_o+h)-f(x_o)+g(x_o+h)-g(x_o)}{h}$
 \end{center}
  \begin{center}
 $=\displaystyle \lim_{h \to 0}\left(\frac{f(x_o+h)-f(x_o)}{h}+\frac{g(x_o+h)-g(x_o)}{h}\right)$
 \end{center}
 \begin{center}
 $=f'(x)+g'(x)$
 \end{center}
 b)
 \begin{center}
 $(uf)'(x)=\displaystyle \lim_{h \to 0}\frac{(uf)(x_o+h)-(uf)(x_o)}{h}$
 \end{center}
 \begin{center}
 $=\displaystyle \lim_{h \to 0}\frac{u(x_o+h)f(x_o+h)-u(x_o)f(x_o)}{h}$
 \end{center}
  \begin{center}
 $=\displaystyle \lim_{h \to 0}\frac{u(x_o+h)\left[f(x_o+h)-f(x_o)\right]+\left[u(x_o+h)-u(x_o)\right]f(x_o)}{h}$
 \end{center}
 \begin{center}
 $=\displaystyle \lim_{h \to 0}\left(\frac{u(x_o+h)\left[f(x_o+h)-f(x_o)\right]}{h}+\frac{\left[u(x_o+h)-u(x_o)\right]f(x_o)}{h}\right)$
 \end{center}
  \begin{center}
 $=u(x)f'(x)+u'(x)f(x)$
  \end{center}
    \begin{center}
 $=u'(x)f(x)+u(x)f'(x)$
  \end{center}
 Las demostraciones de los incisos c) y d) son análogas a los del inciso b), usando las correspondientes operaciones.
\end{proof}
\chapter{Curvas.}

\begin{definition}
Una relación $\sigma:(a,b)\subseteq \mathbb{R} \rightarrow \mathbb{R}^n$ continua en $(a,b)$ se llama trayectoria. A la imagen de $\sigma$ se le llama curva.
\end{definition}

\begin{definition}
Decimos que $\sigma:(a,b)\subseteq \mathbb{R} \rightarrow \mathbb{R}^n$ es una trayectoria simple si $\sigma$ es inyectiva, esto es, que si $\sigma(x_1)=\sigma(x_2)$ entonces $x_1=x_2$. Geométricamente significa que la curva no se cruza a sí misma.
\end{definition}

%reparametrizacion y reparametrizacion por longitud

%teorema que toda reparametrizacion de una curva regular es otra curva regular

%teorema teorema que una trayectoria es regular si y solo si tiene una reparametrizacion por longitud de arco

De aqui en adelante consideraremos unicamente curvas parametrizadas por logitud de arco, y nos referiremos a ellas unicamente como curvas.

\begin{definition}
Si $\sigma:(a,b)\subseteq \mathbb{R} \rightarrow \mathbb{R}^n$ es una trayectoria, el vector tangente $\widehat{t}$ es otra función vectorial asociada a la curva, y se define por
\begin{center}
    $\widehat{t}(s)=\sigma '(s)$
\end{center}
\end{definition}

\begin{proposition}
Si $n:U\subseteq \mathbb{R} \rightarrow \mathbb{R}^n$ es una función vectorial diferenciable cuya imagen $n(x)$ es un vector unitario para todo $x \in U$, entonces $n(t)\cdot n'(t)=0$.
\begin{proof}
 Tenemos que $n(t)\cdot n(t)=1$, si derivamos esta expresión nos queda $n'(t)\cdot n(t)+n(t)\cdot n'(t)=0$, por tanto $2n'(t)\cdot n(t)=0$, y así obtenemos $n(t)\cdot n'(t)=0$.
\end{proof}
\end{proposition}

\begin{definition}
Si $\sigma:(a,b)\subseteq \mathbb{R} \rightarrow \mathbb{R}^n$ es una trayectoria, definimos al vector normal unitario $\widehat{n}$ como
\begin{center}
    $\widehat{n}(s)=\dfrac{\widehat{t} '(s)}{||\widehat{t} '(s)||}=\dfrac{\sigma ''(s)}{||\sigma ''(s)||}$
\end{center}
\end{definition}

\begin{definition}
Si $f:[a,b]\subseteq \mathbb{R} \rightarrow \mathbb{R}^n$ es una trayectoria y $f'(x)\neq 0$, el vector normal unitario $N$ es otra función vectorial asociada a la curva, y se define por
\begin{center}
    $N(x)=\frac{f''(x)}{||f''(x)||}$
\end{center}
\end{definition}
Cuando los dos vectores unitarios $T$ y $N$ están trazados en el punto de la curva $f(x_o)$, determinan un plano llamado plano osculador de la curva. El plano osculador es el plano que pasa por $f(x_o)$ que mejor se adapta a la curva en cada uno de sus puntos. Si la curva es plana, el plano osculador coincide con el plano de la curva. En el espacio, la ecuación del plano osculador de una curva en un punto $(x_o,y_o,z_o)$ es
\begin{center}
    $(x,y,z)=(x_o,y_o,z_o)+\lambda N(x_o,y_o,z_o)+\beta T(x_o,y_o,z_o)$, $\lambda, \beta \in \mathbb{R}$
\end{center}
\begin{definition}
Si $f:[a,b]\subseteq \mathbb{R} \rightarrow \mathbb{R}^n$ es una trayectoria y $f'(x)\neq 0$, el vector binormal unitario $B$ es otra función vectorial asociada a la curva, y se define por
\begin{center}
    $B(x)=\frac{T(x)\times N(x)}{||T(x)\times N(x)||}$
\end{center}
\end{definition}
\begin{definition}
Si $f:[a,b]\subseteq \mathbb{R} \rightarrow \mathbb{R}^n$ es una trayectoria y $f(x_o)\neq 0$, la recta tangente al punto $f(x_o)$ tiene la ecuación
\begin{center}
    $L(t)=f(x_o)+(t-x_o)T(x_o)$, con $t\in \mathbb{R}$
\end{center}
\end{definition}

\end{document}